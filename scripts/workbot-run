#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright Â© 2020 Genome Research Ltd. All rights reserved.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# @author Keith James <kdj@sanger.ac.uk>

# This script finds analyses in the workbot database that have not been
# started and takes them through the steps of:
#
# - Staging the input data
# - Running the analysis
# - Copying the results to iRODS
# - Adding metadata to the results in iRODS
# - Unstaging the input data

import argparse
import logging
from multiprocessing.pool import ThreadPool

from workbot import get_wb_session, get_wh_session
from workbot.base import AnalysisError, make_workbot
from workbot.irods import RodsError
from workbot.schema import WorkInstance, find_work_in_progress
from workbot.utilities import valid_work_type

description = """"""

parser = argparse.ArgumentParser(
        description=description,
        formatter_class=argparse.RawDescriptionHelpFormatter)

#
# parser.add_argument("-a", "--archive-root", type=str, required=True,
#                     help="The root iRODS collection under which the results "
#                          "will be stored")
# parser.add_argument("-s", "--staging-root", type=str, required=True,
#                     help="The local directory root under which files will be "
#                          "staged while working")
parser.add_argument("-t", "--threads", type=int, nargs="?", default=4,
                    help="The number of threads to use. This will be the "
                         "number of analyses running in parallel. Optional, "
                         "defaults to 4. The maximum permitted is 20")

parser.add_argument("-d", "--debug",
                    help="Enable DEBUG level logging to STDERR",
                    action="store_true")
parser.add_argument("-v", "--verbose",
                    help="Enable INFO level logging to STDERR",
                    action='count')

args = parser.parse_args()

log = logging.getLogger("main")
level = logging.ERROR
if args.debug:
    level = logging.DEBUG
    logging.getLogger("workbot").setLevel(logging.DEBUG)

if args.verbose:
    level = logging.INFO

    if args.verbose > 1:
        logging.getLogger("workbot").setLevel(logging.INFO)

    if args.verbose > 2:
        logging.getLogger("sqlalchemy.engine").setLevel(logging.INFO)

logging.basicConfig(format="%(asctime)s %(levelname)s %(threadName)s - "
                           "%(message)s", level=level)


def fn(workinstance_id) -> bool:
    sess = get_wb_session()
    mlwh_sess = get_wh_session()

    success = False
    try:
        wi = sess.query(WorkInstance). \
            filter(WorkInstance.id == workinstance_id).one()

        if wi.is_started():
            # This is bad and shouldn't happen. We probably crashed after
            # starting the analysis during a previous run. Or possibly more
            # than one runner has been started on the same database.
            raise AnalysisError("Found work instance {} "
                                "in Started state".format(workinstance_id))

        log.info("Working on: {}, {} [{}]".format(wi, wi.input_path, wi.state))

        wt = valid_work_type(wi.work_type)
        wb = make_workbot(wt)
        wb.run(sess, wi, mlwh_session=mlwh_sess)

        success = True
    except RodsError as e:
        log.error(e.message)
    finally:
        sess.close()
        mlwh_sess.close()

    return success


def main():
    num_threads = args.threads
    if num_threads > 20:
        num_threads = 20

    sess = get_wb_session()

    try:
        in_progress = find_work_in_progress(sess)
        fn_args = [wi.id for wi in in_progress]

        with ThreadPool(num_threads) as p:
            succeeded = p.map(fn, fn_args)
    finally:
        sess.close()

    num_errors = succeeded.count(False)
    if num_errors > 0:
        log.error("Performed {} operations "
                  "with {} errors".format(len(in_progress), num_errors))
        exit(1)


if __name__ == "__main__":
    main()
